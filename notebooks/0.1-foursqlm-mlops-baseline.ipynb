{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-04T05:20:55.705293Z","iopub.execute_input":"2022-05-04T05:20:55.705883Z","iopub.status.idle":"2022-05-04T05:20:55.710929Z","shell.execute_reply.started":"2022-05-04T05:20:55.705844Z","shell.execute_reply":"2022-05-04T05:20:55.709947Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Префиксный код (импорты, вспомогательные функции/классы/гиперпараметры)","metadata":{}},{"cell_type":"code","source":"# Imports\nimport numpy as np\nimport pandas as pd\nimport haversine as hs\nimport random\n\n# Imports from\nfrom haversine import Unit\nfrom sklearn.model_selection import GroupKFold\nfrom fuzzywuzzy import fuzz\nfrom xgboost import XGBClassifier","metadata":{"execution":{"iopub.status.busy":"2022-05-02T16:32:40.238475Z","iopub.execute_input":"2022-05-02T16:32:40.238733Z","iopub.status.idle":"2022-05-02T16:32:41.539092Z","shell.execute_reply.started":"2022-05-02T16:32:40.238693Z","shell.execute_reply":"2022-05-02T16:32:41.538405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fix all random seeds\nrandom.seed(42)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T16:32:41.540807Z","iopub.execute_input":"2022-05-02T16:32:41.541334Z","iopub.status.idle":"2022-05-02T16:32:41.546388Z","shell.execute_reply.started":"2022-05-02T16:32:41.541285Z","shell.execute_reply":"2022-05-02T16:32:41.54508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Custom Func's/Class's\n\ndef jaccard(list_a: list, list_b: list) -> float:\n    a = set(list_a)\n    b = set(list_b)\n    return len(a & b) / len(a | b)\n\n\ndef jaccard_score(df_sub_a: pd.DataFrame, df_sub_b: pd.DataFrame) -> float:\n    \n    assert len(df_sub_a) == len(df_sub_b)\n    df = pd.merge(df_sub_a, df_sub_b, on='id', suffixes=['_a','_b'])\n    return (df.apply(lambda x: jaccard(x.matches_a.split(), x.matches_b.split()),\n                     axis=1)).mean()\n\n\ndef get_submission_predict(df_original: pd.DataFrame, \n                           df_pairs: pd.DataFrame, \n                           labels: np.array,\n                           pairs_drop_orders_dublicates = False) -> pd.DataFrame:\n    \n    # task: понял поздно, уже после написания, но есть проблема, нужно ее решить,\n    #       переписать в единственном варианте, либо добавить возможность возвращать\n    #       оба варианта, в зависимости от перданного параметра (и проверить на\n    #       реальных сабмитах, какой вариант дает больший скор);\n    #       проблема: если модель предсказала, что (id1, id2) и (id2, id3) дублиаты,\n    #       а (id1, id3) нет, то в текущей реализации в сабмит добавятся строки \n    #       (id1, [id1, id2]), (id2, [id2, id1, id3], (id3, [id3, id2]), хотя на\n    #       самом деле они либо все дубликаты, либо где то предсказание ошибочно.\n    \n    # task: возможно медленно работает, протестировать с прошлой версией во времени\n    \n    # формируем датасет из пар, для которых match/label == 1\n    df_pairs = df_pairs[['id_1', 'id_2']]\n    df_pairs['match'] = labels\n    df_pairs = df_pairs[df_pairs.match == 1][['id_1','id_2']]\n    \n    # если мы оставляли пары только в одном направлении (id_1, id_2),\n    # то возвращаем что бы они были в обоих (id_1, id_2) и (id_2, id_1)\n    if pairs_drop_orders_dublicates:\n        df_pairs = (pd.concat([df_pairs, \n                               df_pairs.rename(columns={'id_1': 'id_2', \n                                                        'id_2': 'id_1'})])\n                    .drop_duplicates()) #drop_duplicates не обязателен\n    \n    # добавляем сапоставление  id  самому себе, т.к. этого требует выходной\n    # формат\n    pairs_one_to_one = pd.DataFrame({'id_1': df_pairs.id_1.unique()})\n    pairs_one_to_one['id_2'] = pairs_one_to_one.id_1\n    df_pairs = pd.concat([pairs_one_to_one, df_pairs])\n    \n    # переводим в формат id, matches, где в matches через пробел перечислены все \n    # найденные дубликаты (в том числе сам id попадет в matches)\n    df_pairs = (df_pairs.groupby('id_1').id_2.agg(' '.join).to_frame().reset_index()\n                .rename(columns={'id_1': 'id', 'id_2': 'matches'}))\n    \n    # в df_pairs остались только id, для которых найдены дубликаты, мерджим со \n    # всеми id из исходного датасета и добавляем в matchs id самого себя, для \n    # тех id, которые не попали в df_pairs (после merge у них matches == NaN)\n    df_submission = pd.merge(df_original['id'], df_pairs, on='id', how='left')\n    df_submission['matches'] = df_submission.matches.fillna(df_submission.id)\n    \n    assert len(df_submission) == len(df_original)\n    \n    return df_submission\n\n\ndef get_submission_true(df_original: pd.DataFrame) -> pd.DataFrame:\n    df_original = df_original[['id', 'point_of_interest']]\n    df_poi_matches = (df_original.groupby('point_of_interest').id.agg(' '.join)\n                      .to_frame().reset_index().rename(columns={'id': 'matches'}))\n    return pd.merge(df_original, df_poi_matches, \n                    on='point_of_interest', how='left')[['id','matches']]\n\ndef get_pairs_metrics(df_original: pd.DataFrame, \n                      df_pairs: pd.DataFrame, \n                      labels: np.array,\n                      pairs_drop_orders_dublicates = False) -> dict:\n    metrics = {}\n    submission_true = get_submission_true(df_original)\n    submission_pairs_max_true = get_submission_predict(df_original, \n                                                       df_pairs, \n                                                       labels, \n                                                       pairs_drop_orders_dublicates)\n    metrics['Jaccard (max)'] = jaccard_score(submission_true, submission_pairs_max_true)\n    \n    return metrics\n\ndef generate_pairs_df(df_dataset: pd.DataFrame, drop_order_dub=False, get_metrics = False, real_test = False) -> (pd.DataFrame, dict):\n    # Отбираем только колонки, которые планируем использовать в дальнейшем\n    # task: перенести в параметры/гиперпараметры?\n    \n    FIRST_COLUMN_SELECTION = ['id', 'name', 'latitude', 'longitude', 'country', 'city', 'categories', 'point_of_interest']\n    \n    # в реальном тесте отсутсвует 'point_of_interest', удаляем из наших колонок\n    if real_test:\n        FIRST_COLUMN_SELECTION.remove('point_of_interest')\n    \n    \n    df_dataset = df_dataset[FIRST_COLUMN_SELECTION]\n\n    # task: Изучить возможности sklearn для подобных целей, скорей всего это будет наилучший вариант (примерные ключевые слова:\n    # sklearn neighbors by coordinate)\n    FIRST_COORD_ROUND = 3 # сотые ~= 1 км, тысячные ~= 0.1 км\n\n    # task: Если использовать подобный подход, нужно обязательно производить с перекрытием (придумать как)\n    # task: Устранить SettingWithCopyWarning\n\n    # Первоначальный вариант (в 'lat_lon_round' мы получим строкивые представления округленных координат):\n    # df_dataset.loc['lat_lon_group'] = (df_dataset.latitude.map(lambda x: str(round(x,FIRST_COORD_ROUND))) + '_' + \n    #                                    df_dataset.longitude.map(lambda x: str(round(x,FIRST_COORD_ROUND))))\n    # Альтернативный вариант (результат аналогичный, за исключенем того, что в 'lat_lon_round' мы получим номера групп):\n    df_dataset['lat_lon_group'] = df_dataset.groupby([df_dataset.latitude.round(FIRST_COORD_ROUND), \n                                                      df_dataset.longitude.round(FIRST_COORD_ROUND)]).ngroup()\n    \n    ## Формирование пар-кандидитов\n    columns_to_pairs = ['lat_lon_group'] #колонки для совоставления в пары\n    df_pairs = pd.merge(df_dataset, df_dataset, on=columns_to_pairs, suffixes=['_1','_2'])\n\n    # Оставляем пары только в одном направлении (id_1, id_2) или в обоих (id_1, id_2) и (id_2, id_1)\n    if drop_order_dub:\n        df_pairs = df_pairs[df_pairs.id_1 < df_pairs.id_2]\n    else: #удаляем только полные дубликаты (id_1, id_1)\n        df_pairs = df_pairs[df_pairs.id_1 != df_pairs.id_2]\n    \n    \n    #Generate metrics for current candidates\n    metrics = {}\n    if get_metrics and not real_test:\n        labels = np.array(get_match_label(df_pairs))\n        metrics = get_pairs_metrics(df_dataset, \n                                    df_pairs, \n                                    labels,\n                                    drop_order_dub)\n\n    return df_pairs, metrics\n\ndef add_feauture_geo_distance(df_pairs: pd.DataFrame, normalize=False, prefix='ftr_') -> pd.DataFrame:\n    # Считаем расстояние в км между точками\n    # task: Возможно нет смысла считать точно через haversine (с учетом шарообразности земли), \n    # можно считать более грубо, но быстрее\n    \n    df_pairs[f'{prefix}geo_distance'] = df_pairs.apply(lambda x: hs.haversine((x.latitude_1,x.longitude_1), \n                                                 (x.latitude_2,x.longitude_2), \n                                                 unit=Unit.KILOMETERS), axis=1)\n    return df_pairs\n\n\ndef add_feauture_levenshtein_distance(df_pairs: pd.DataFrame, normalize=False, prefix='ftr_') -> pd.DataFrame:\n    # Levenshtein distance of names\n    df_pairs[f'{prefix}name_levenshtein'] = df_pairs.apply(lambda x: fuzz.token_set_ratio(x.name_1,\n                                                                                          x.name_2), axis=1)\n    return df_pairs\n\n\ndef run_futures_pipeline(dataset: pd.DataFrame, futures_pipeline: list, prefix='ftr_') -> pd.DataFrame:\n    for step in futures_pipeline:\n        dataset = step['func'](dataset, prefix=prefix, **step['params'])\n    future_columns = [col for col in dataset.columns if col.startswith(prefix)]\n    return dataset.reset_index(drop=True), future_columns\n\n\ndef get_match_label(dataset: pd.DataFrame) -> pd.Series: # 1 = match, 0 = not match\n    #Наша целевая переменная (label/target)\n    return (dataset['point_of_interest_1'] == dataset['point_of_interest_2']).astype(int)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-02T16:32:41.54785Z","iopub.execute_input":"2022-05-02T16:32:41.548257Z","iopub.status.idle":"2022-05-02T16:32:41.581993Z","shell.execute_reply.started":"2022-05-02T16:32:41.548221Z","shell.execute_reply":"2022-05-02T16:32:41.581393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.path.join('.',\"data\", \"raw\")","metadata":{"execution":{"iopub.status.busy":"2022-05-04T05:40:37.226077Z","iopub.execute_input":"2022-05-04T05:40:37.226956Z","iopub.status.idle":"2022-05-04T05:40:37.233776Z","shell.execute_reply.started":"2022-05-04T05:40:37.226905Z","shell.execute_reply":"2022-05-04T05:40:37.232999Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"os.path.join('.',\"output\",\"log.txt\")","metadata":{"execution":{"iopub.status.busy":"2022-05-04T05:37:14.302130Z","iopub.execute_input":"2022-05-04T05:37:14.303098Z","iopub.status.idle":"2022-05-04T05:37:14.309210Z","shell.execute_reply.started":"2022-05-04T05:37:14.303049Z","shell.execute_reply":"2022-05-04T05:37:14.308583Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"PATH_TO_RAW_DATA = os.path.join('.',\"data\", \"raw\")","metadata":{"execution":{"iopub.status.busy":"2022-05-04T05:40:48.783285Z","iopub.execute_input":"2022-05-04T05:40:48.784325Z","iopub.status.idle":"2022-05-04T05:40:48.789426Z","shell.execute_reply.started":"2022-05-04T05:40:48.784262Z","shell.execute_reply":"2022-05-04T05:40:48.788526Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"os.path.join(PATH_TO_RAW_DATA, 'train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-05-04T05:41:12.205887Z","iopub.execute_input":"2022-05-04T05:41:12.206351Z","iopub.status.idle":"2022-05-04T05:41:12.212388Z","shell.execute_reply.started":"2022-05-04T05:41:12.206306Z","shell.execute_reply":"2022-05-04T05:41:12.211571Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"## Hyperparameters\n\n# Задаем пути до директории с train/test.csv (в записимости от варианта запуска ноутбука)\nif 'KAGGLE_KERNEL_RUN_TYPE' in os.environ:\n    PATH_TO_RAW_DATA = '/kaggle/input/foursquare-location-matching'\nelse:\n    #./data/raw\n    PATH_TO_RAW_DATA = os.path.join('.',\"data\", \"raw\")\n    \n# Количество частей, на которые будет разбит train датасет, \n# одна часть уйдет на split_test, остальные на split_train\n# 3 = 1/2 (или 33%/88%), 4 = 1/3 (или 25%/75) и т.д.\nTRAIN_TEST_N_SPLITS = 3\n\n# Перезапуск всего обучения на полном train.csv и формирование/сохранение submission.csv\n# на основе test.csv, необходимо для реального сабмита на каггле\nGENERATE_SUBMISSION_CSV = True","metadata":{"execution":{"iopub.status.busy":"2022-05-02T16:32:41.583513Z","iopub.execute_input":"2022-05-02T16:32:41.583753Z","iopub.status.idle":"2022-05-02T16:32:41.601279Z","shell.execute_reply.started":"2022-05-02T16:32:41.583726Z","shell.execute_reply":"2022-05-02T16:32:41.600404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Обработка датасетов","metadata":{"execution":{"iopub.status.busy":"2022-04-29T06:43:20.590215Z","iopub.execute_input":"2022-04-29T06:43:20.590653Z","iopub.status.idle":"2022-04-29T06:43:20.593661Z","shell.execute_reply.started":"2022-04-29T06:43:20.590621Z","shell.execute_reply":"2022-04-29T06:43:20.593068Z"}}},{"cell_type":"markdown","source":"### - Разбиваем исходный Raw Train датасет (train.csv) на Train/Test (-> имеем на выходе split_train/split_test)","metadata":{}},{"cell_type":"code","source":"# Разбиваем так, что бы объекты с одинаковым POI не раскидывались в разные выборки\n\ntrain = pd.read_csv(os.path.join(PATH_TO_RAW_DATA, 'train.csv'))\n\n# Подход по применению GroupKFold для подобных целей подсмотрел здесь:\n# https://www.kaggle.com/code/ryotayoshinobu/foursquare-lightgbm-baseline\n\nkf = GroupKFold(n_splits=TRAIN_TEST_N_SPLITS)\nfor i, (trn_idx, val_idx) in enumerate(kf.split(train, train['point_of_interest'], train['point_of_interest'])):\n    train.loc[val_idx, \"parts\"] = str(i)\n    \nsplit_test = train[train.parts == '1'].drop(columns='parts')\nsplit_train = train[~(train.parts == '1')].drop(columns='parts')\n\nprint(f'Our train size: {len(split_train)}, Our test size: {len(split_test)}')\n\n#Освобождаем память\ndel train","metadata":{"execution":{"iopub.status.busy":"2022-05-02T09:43:27.936763Z","iopub.execute_input":"2022-05-02T09:43:27.937325Z","iopub.status.idle":"2022-05-02T09:43:45.855175Z","shell.execute_reply.started":"2022-05-02T09:43:27.937287Z","shell.execute_reply":"2022-05-02T09:43:45.854183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### - Предобработка датасета, отбор, формирование пар-кандидатов для сравнения (-> датасет пар-кандидатов)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T06:27:54.356432Z","iopub.execute_input":"2022-04-29T06:27:54.356748Z","iopub.status.idle":"2022-04-29T06:27:54.360855Z","shell.execute_reply.started":"2022-04-29T06:27:54.356714Z","shell.execute_reply":"2022-04-29T06:27:54.360228Z"}}},{"cell_type":"code","source":"PAIRS_DROP_ORDER_DUBLICATES = True\n\npairs_train, pairs_metrics = generate_pairs_df(split_train, PAIRS_DROP_ORDER_DUBLICATES, get_metrics=True)\nprint(pairs_metrics)\npairs_train","metadata":{"execution":{"iopub.status.busy":"2022-05-02T09:43:45.85642Z","iopub.execute_input":"2022-05-02T09:43:45.856649Z","iopub.status.idle":"2022-05-02T09:44:27.746997Z","shell.execute_reply.started":"2022-05-02T09:43:45.856622Z","shell.execute_reply":"2022-05-02T09:44:27.746112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### - Фиче инжинеринг датасета пар-кандидатов, формирование X, y (-> X, y, готовые для передачи в модель)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T06:27:54.356432Z","iopub.execute_input":"2022-04-29T06:27:54.356748Z","iopub.status.idle":"2022-04-29T06:27:54.360855Z","shell.execute_reply.started":"2022-04-29T06:27:54.356714Z","shell.execute_reply":"2022-04-29T06:27:54.360228Z"}}},{"cell_type":"code","source":"## Формирование датасета, подходящего для передачи в модель\npairs_futures_pipeline = [\n    {'func': add_feauture_geo_distance,\n     'params': {}},\n    {'func': add_feauture_levenshtein_distance,\n     'params': {}}]\n\n#Генерируем все необходимые фичи\npairs_train, future_columns = run_futures_pipeline(pairs_train, pairs_futures_pipeline)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T09:44:27.748182Z","iopub.execute_input":"2022-05-02T09:44:27.748404Z","iopub.status.idle":"2022-05-02T09:46:33.990742Z","shell.execute_reply.started":"2022-05-02T09:44:27.748377Z","shell.execute_reply":"2022-05-02T09:46:33.98963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Нормализация фичей (или нужно сразу при формировании фичей?)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T09:46:33.992112Z","iopub.execute_input":"2022-05-02T09:46:33.992371Z","iopub.status.idle":"2022-05-02T09:46:33.997693Z","shell.execute_reply.started":"2022-05-02T09:46:33.992341Z","shell.execute_reply":"2022-05-02T09:46:33.996647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Формируем X, y для дальнейшей передачи в модель\n\ny = get_match_label(pairs_train)\nX = pairs_train[future_columns]\n\n# оставляем в памяти (для очистки лишней памяти) только те, колонки, \n# которые нам понадобятся в дальнейшем (для формирования submission)\npairs_train = pairs_train[['id_1', 'id_2']]","metadata":{"execution":{"iopub.status.busy":"2022-05-02T09:46:33.999197Z","iopub.execute_input":"2022-05-02T09:46:33.999416Z","iopub.status.idle":"2022-05-02T09:46:34.400651Z","shell.execute_reply.started":"2022-05-02T09:46:33.999389Z","shell.execute_reply":"2022-05-02T09:46:34.399385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### - Обработка датасета отложенной выборки split_test для итоговой оценки модели (-> )","metadata":{"execution":{"iopub.status.busy":"2022-04-29T06:58:44.051162Z","iopub.execute_input":"2022-04-29T06:58:44.051456Z","iopub.status.idle":"2022-04-29T06:58:44.055366Z","shell.execute_reply.started":"2022-04-29T06:58:44.051422Z","shell.execute_reply":"2022-04-29T06:58:44.054391Z"}}},{"cell_type":"code","source":"pairs_test, pairs_metrics = generate_pairs_df(split_test, PAIRS_DROP_ORDER_DUBLICATES, get_metrics=True)\n\nprint(pairs_metrics)\n\npairs_test, future_columns = run_futures_pipeline(pairs_test, pairs_futures_pipeline)\n\ny_test = get_match_label(pairs_test)\nX_test = pairs_test[future_columns]\n\n# оставляем в памяти (для очистки лишней памяти) только те, колонки, \n# которые нам понадобятся в дальнейшем (для формирования submission)\npairs_test = pairs_test[['id_1', 'id_2']]","metadata":{"execution":{"iopub.status.busy":"2022-05-02T09:46:34.403922Z","iopub.execute_input":"2022-05-02T09:46:34.404307Z","iopub.status.idle":"2022-05-02T09:47:32.646005Z","shell.execute_reply.started":"2022-05-02T09:46:34.404259Z","shell.execute_reply":"2022-05-02T09:47:32.645006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Обучение модели (-> сохраненная в файл модель)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T07:02:30.618258Z","iopub.execute_input":"2022-04-29T07:02:30.61852Z","iopub.status.idle":"2022-04-29T07:02:30.622406Z","shell.execute_reply.started":"2022-04-29T07:02:30.618493Z","shell.execute_reply":"2022-04-29T07:02:30.621479Z"}}},{"cell_type":"code","source":"# Model params\nmodel_params = {'random_state': 42,\n                'n_estimators': 10,\n                'verbosity': 0}\n\n# Define the model\nmodel = XGBClassifier(**model_params)\n\n# Fit the model\nmodel.fit(X, y)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T09:47:32.647613Z","iopub.execute_input":"2022-05-02T09:47:32.648169Z","iopub.status.idle":"2022-05-02T09:47:36.994574Z","shell.execute_reply.started":"2022-05-02T09:47:32.648119Z","shell.execute_reply":"2022-05-02T09:47:36.993829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Оценка модели на отложенной выборке (-> Score на отложенной выборке)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T07:03:58.305628Z","iopub.execute_input":"2022-04-29T07:03:58.306023Z","iopub.status.idle":"2022-04-29T07:03:58.310055Z","shell.execute_reply.started":"2022-04-29T07:03:58.305988Z","shell.execute_reply":"2022-04-29T07:03:58.309275Z"}}},{"cell_type":"code","source":"# Get predictions\ny_pred = model.predict(X_test)\n\n# Accuracy (not all id's) удалить, т.к. не учитывает часть id\nprint(np.mean(y_pred == np.array(y_test)))","metadata":{"execution":{"iopub.status.busy":"2022-05-02T09:47:36.998336Z","iopub.execute_input":"2022-05-02T09:47:37.000805Z","iopub.status.idle":"2022-05-02T09:47:37.065976Z","shell.execute_reply.started":"2022-05-02T09:47:37.000759Z","shell.execute_reply":"2022-05-02T09:47:37.065276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_true = get_submission_true(split_test)\nsubmission_pred = get_submission_predict(split_test, pairs_test, y_pred, PAIRS_DROP_ORDER_DUBLICATES)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T09:47:37.069941Z","iopub.execute_input":"2022-05-02T09:47:37.072265Z","iopub.status.idle":"2022-05-02T09:47:41.509773Z","shell.execute_reply.started":"2022-05-02T09:47:37.072197Z","shell.execute_reply":"2022-05-02T09:47:41.508598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"jaccard_score(submission_true, submission_pred)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T09:47:41.511262Z","iopub.execute_input":"2022-05-02T09:47:41.511587Z","iopub.status.idle":"2022-05-02T09:47:53.924868Z","shell.execute_reply.started":"2022-05-02T09:47:41.51155Z","shell.execute_reply":"2022-05-02T09:47:53.924054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Перезапуск всего пайплайна на полном датасете для целей сабмита на каггле (-> submission.csv для сабмита на каггле)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T07:03:58.305628Z","iopub.execute_input":"2022-04-29T07:03:58.306023Z","iopub.status.idle":"2022-04-29T07:03:58.310055Z","shell.execute_reply.started":"2022-04-29T07:03:58.305988Z","shell.execute_reply":"2022-04-29T07:03:58.309275Z"}}},{"cell_type":"code","source":"if GENERATE_SUBMISSION_CSV:\n    train = pd.read_csv(os.path.join(PATH_TO_RAW_DATA, 'train.csv'))\n\n    \n    ## Отбираем кандидатов и формируем парный датасет\n    pairs_train, pairs_metrics = generate_pairs_df(train, PAIRS_DROP_ORDER_DUBLICATES, get_metrics=True)\n    print(pairs_metrics)\n\n    \n    ## Генерируем все необходимые фичи\n    pairs_train, future_columns = run_futures_pipeline(pairs_train, pairs_futures_pipeline)\n    \n    \n    ## Формируем X, y для дальнейшей передачи в модель\n    y = get_match_label(pairs_train)\n    X = pairs_train[future_columns]\n\n    # оставляем в памяти (для очистки лишней памяти) только те, колонки, \n    # которые нам понадобятся в дальнейшем (для формирования submission)\n    pairs_train = pairs_train[['id_1', 'id_2']]\n    \n    \n    ## Обучаем модель\n    \n    # Model params\n    model_params = {'random_state': 42,\n                    'n_estimators': 10,\n                    'verbosity': 0}\n\n    # Define the model\n    model = XGBClassifier(**model_params)\n\n    # Fit the model\n    model.fit(X, y)\n    \n    \n    ## Генерируем предсказания и финальный submission.csv\n    test = pd.read_csv(os.path.join(PATH_TO_RAW_DATA, 'test.csv')\n    \n    # Т.к. публичный (в отличе от приветного) test.csv содержит всех 5 разрозненных записей, которые даже не\n    # попадают в кандидаты, весь пайплайн рушится, по причине пустого парного датасета,\n    # что бы это обойти, проверяем на количество строк (с целью определить имеем мы дело с публичным или \n    # приватным test.csv) и в случае публичного, дублируем объекты изменив предварительно id\n    if len(test) == 5:\n        temp = test.copy()\n        temp.id = temp.id + '_'\n        test = pd.concat([test, temp])\n    \n    pairs_test, _ = generate_pairs_df(test, PAIRS_DROP_ORDER_DUBLICATES, real_test=True)\n\n    pairs_test, future_columns = run_futures_pipeline(pairs_test, pairs_futures_pipeline)\n\n    X_test = pairs_test[future_columns]\n\n    # оставляем в памяти (для очистки лишней памяти) только те, колонки, \n    # которые нам понадобятся в дальнейшем (для формирования submission)\n    pairs_test = pairs_test[['id_1', 'id_2']]\n    \n    # Get predictions\n    y_pred = model.predict(X_test)\n\n    submission_pred = get_submission_predict(test, pairs_test, y_pred, PAIRS_DROP_ORDER_DUBLICATES)\n    \n    submission_pred.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T09:47:53.926181Z","iopub.execute_input":"2022-05-02T09:47:53.92643Z","iopub.status.idle":"2022-05-02T09:54:05.93671Z","shell.execute_reply.started":"2022-05-02T09:47:53.9264Z","shell.execute_reply":"2022-05-02T09:54:05.935396Z"},"trusted":true},"execution_count":null,"outputs":[]}]}